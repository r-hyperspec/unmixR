<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{VCA with unmixR}
%\VignetteKeywords{hyperspectral unmixing, vertex component analysis, VCA}
%\VignetteDepends{plot3D, scatterplot3d}
 -->

<h1 id="vca-with-unmixr">VCA with unmixR</h1>
<p>Anton Belov, July 1, 2016</p>
<pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">library</span>(plot3D)
    <span class="kw">library</span>(hyperSpec, <span class="dt">quietly =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>## Use suppressPackageStartupMessages() to eliminate package startup
## messages.</code></pre>
<pre><code>## Package hyperSpec, version 0.98-20161118
## 
## To get started, try
##    vignette (&quot;introduction&quot;, package = &quot;hyperSpec&quot;)
##    package?hyperSpec 
##    vignette (package = &quot;hyperSpec&quot;)
## 
## If you use this package please cite it appropriately.
##    citation(&quot;hyperSpec&quot;)
## will give you the correct reference.
## 
## The project homepage is http://hyperspec.r-forge.r-project.org</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">    d &lt;-<span class="st"> </span>unmixR:::.testdata$x
    <span class="kw">str</span>(d)</code></pre>
<pre><code>##  AsIs [1:10, 1:3] 0 1 2 3 0 1 2 0 1 0 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ samples    : chr [1:10] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   ..$ wavelengths: chr [1:3] &quot;L1&quot; &quot;L2&quot; &quot;L3&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">scatter3D</span>(d[, <span class="dv">1</span>], d[, <span class="dv">2</span>], d[, <span class="dv">3</span>], <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">col =</span> <span class="kw">matlab.dark.palette</span>(), <span class="dt">phi =</span> <span class="dv">50</span>, <span class="dt">theta =</span> <span class="dv">110</span>)</code></pre>
<div class="figure">
<img src="figure/unnamed-chunk-1-1.png" alt="plot of chunk unnamed-chunk-1" /><p class="caption">plot of chunk unnamed-chunk-1</p>
</div>
<h2 id="dimensionality-reduction">Dimensionality Reduction</h2>
<p>The algorithm uses two dimensionality reduction techniques. The choice depends on the signal to noise ratio of data. The threshold value is equal to <span class="math">15 + 10log<em>p</em></span> The dimensionality reduction function not only reduces dimensionality of data but also transforms it to amplify noise.</p>
<pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">library</span>(unmixR, <span class="dt">quietly =</span> <span class="ot">TRUE</span>)
    <span class="kw">dim</span>(d)</code></pre>
<pre><code>## [1] 10  3</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">    endNum &lt;-<span class="st"> </span><span class="dv">3</span>
    snrThreshhold &lt;-<span class="st"> </span><span class="dv">15</span> +<span class="st"> </span><span class="dv">10</span> *<span class="st"> </span><span class="kw">log10</span>(endNum)
    sameReduced &lt;-<span class="st"> </span><span class="kw">dimensionalityReduction</span>(d, endNum, snrThreshhold +<span class="st"> </span><span class="dv">1</span>)
    lowerReduced &lt;-<span class="st"> </span><span class="kw">dimensionalityReduction</span>(d, endNum, snrThreshhold -<span class="st"> </span><span class="dv">1</span>)</code></pre>
<h2 id="plotting-the-data">Plotting the Data</h2>
<pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">library</span>(scatterplot3d, <span class="dt">quietly =</span> <span class="ot">TRUE</span>)
    <span class="kw">colnames</span>(sameReduced) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;z&quot;</span>)
    <span class="kw">colnames</span>(lowerReduced) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;z&quot;</span>)
    <span class="kw">scatterplot3d</span>(sameReduced, <span class="dt">main =</span> <span class="st">&quot;given dimensionality reduced data&quot;</span>)</code></pre>
<div class="figure">
<img src="figure/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3" /><p class="caption">plot of chunk unnamed-chunk-3</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">scatterplot3d</span>(lowerReduced, <span class="dt">main =</span> <span class="st">&quot;lower dimensionality reduced data&quot;</span>)</code></pre>
<div class="figure">
<img src="figure/unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4" /><p class="caption">plot of chunk unnamed-chunk-4</p>
</div>
<p>Using the second approach, the algorithm projects the data onto a subspace of even lower dimensionality and then sets the &quot;missing&quot; dimension values to a certain value. That is why points colored in red have the same z value, because the data was reduced to the dimensionality of 2 (x and y) and then the z value was set to a certain number.</p>
<pre class="sourceCode r"><code class="sourceCode r">    my3dplot &lt;-<span class="st"> </span><span class="kw">scatterplot3d</span>(lowerReduced, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>,
      <span class="dt">zlim =</span> <span class="kw">c</span>(-<span class="dv">1</span>, <span class="dv">3</span>), <span class="dt">main =</span> <span class="st">&quot;transformed data&quot;</span>)
    my3dplot$<span class="kw">points3d</span>(sameReduced, <span class="dt">type =</span> <span class="st">&quot;h&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
    <span class="kw">legend</span>(<span class="dt">x =</span> <span class="st">&quot;bottomright&quot;</span>, <span class="dt">pch =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>),
      <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;same&quot;</span>, <span class="st">&quot;lower&quot;</span>))</code></pre>
<div class="figure">
<img src="figure/unnamed-chunk-5-1.png" alt="plot of chunk unnamed-chunk-5" /><p class="caption">plot of chunk unnamed-chunk-5</p>
</div>
<p>Since the noise in this example is very low the algorithm will use the first approach.</p>
<h2 id="the-vca-process-illustrated">The VCA Process, Illustrated</h2>
<p>The VCA algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li>The data is reduced to a dimensionality equal to <span class="math"><em>p</em></span> where <span class="math"><em>p</em></span> is the desired (estimated) number of endmembers. As mentioned above, the details of the reduction depend upon the signal-to-noise ratio of the raw data.</li>
<li>Initialize <span class="math"><em>A</em></span>, a <span class="math"><em>p</em> × <em>p</em></span> matrix that will store the endmembers. The first column is set to a constant, which represents an initial &quot;fake&quot; endmember to get the process started.</li>
<li>For <span class="math"><em>i</em></span> from 1 to <span class="math"><em>p</em></span>:</li>
</ol>
<ul>
<li>Calculate a reference vector orthogonal to the subspace spanned by columns of <span class="math"><em>A</em></span>. This vector will pass through (0,0,...,0).</li>
<li>Project all the data points onto this reference vector.</li>
<li>Find which data point's projection onto the reference vector is furthest from the origin. This is equivalent to the data point which has the maximum absolute projection onto the reference vector.</li>
<li>Let <span class="math"><em>k</em></span> be the index of that data point in the dataset. Set the <span class="math"><em>i</em></span>-th column of <span class="math"><em>A</em></span> to <span class="math"><em>k</em></span>-th column of data. This is one of the endmembers.</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Return <span class="math"><em>A</em></span>.</li>
</ol>
<p>The following plots illustrate the process for a 3-dimensional data set consisting of a number of points which lie on a plane and form a triangle.</p>
<p>The system is initialized with a &quot;fake&quot; endmember with coordinates <span class="math">(0, 0, 1)</span> and a reference vector <span class="math"><em>f</em></span> which is orthogonal to this endmember (point) is computed. Then, each data point is projected onto this reference vector. The data point whose projection intersection with <span class="math"><em>f</em></span> is farthest from the origin is selected as the first (real) endmember (and the fake endmember is discarded). The next plot shows these steps. The first endmember is at the lower-left.</p>
<div class="figure">
<img src="figure/unnamed-chunk-8-1.png" alt="plot of chunk unnamed-chunk-8" /><p class="caption">plot of chunk unnamed-chunk-8</p>
</div>
<p>The first real endmember is then used to construct a new reference vector <span class="math"><em>f</em></span> and once again the data points are projected onto <span class="math"><em>f</em></span> and the projection intersection with <span class="math"><em>f</em></span> which is farthest from the origin is selected as the next endmember. In the following plot, the 2nd endmember selected is the top-most data point.</p>
<div class="figure">
<img src="figure/unnamed-chunk-9-1.png" alt="plot of chunk unnamed-chunk-9" /><p class="caption">plot of chunk unnamed-chunk-9</p>
</div>
<p>With two endmembers identified, we continue the process starting from the most recently identified endmember. In this next plot, the 3rd endmember is the right-most data point. It's projection onto the reference vector <span class="math"><em>f</em></span> is very short and not visible as the data point nearly falls on <span class="math"><em>f</em></span>. In this plot and the next, we are carrying along the vectors which were used to construct the reference vectors <span class="math"><em>f</em></span> at each step.</p>
<div class="figure">
<img src="figure/unnamed-chunk-10-1.png" alt="plot of chunk unnamed-chunk-10" /><p class="caption">plot of chunk unnamed-chunk-10</p>
</div>
<p>Finally all endmembers have been identified.</p>
<div class="figure">
<img src="figure/unnamed-chunk-11-1.png" alt="plot of chunk unnamed-chunk-11" /><p class="caption">plot of chunk unnamed-chunk-11</p>
</div>
<p>If this process were extended to <span class="math"><em>p</em></span>-dimensions, each reference vector <span class="math"><em>f</em></span> would be a line in the <span class="math"><em>p</em></span>-dimensional space. Thus the process would be to choose a point, construct an orthogonal vector <span class="math"><em>f</em></span>, and determine which data point has the most extreme projection onto this vector. That point is chosen as an endmember and the process is repeated until all the desired endmembers have been identified.</p>
